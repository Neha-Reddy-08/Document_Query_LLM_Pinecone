{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #convert into chunks\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94ab4250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() #this will load all ur env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ced0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "882bdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the document\n",
    "\n",
    "def read_doc(directory):\n",
    "    loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cca5146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc= read_doc('documents/')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f796da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget 2023-2024 \n",
      " \n",
      "Speech of \n",
      "Nirmala Sitharaman \n",
      "Minister of Finance \n",
      "February 1, 2023 \n",
      "Hon’ble Speaker,  \n",
      " I present the Budget for 2023-24. This is the first Budget in Amrit \n",
      "Kaal. \n",
      "Introduction \n",
      "1. This Budget hopes to build on the foundation laid in the previous \n",
      "Budget, and the blueprint drawn for India@100. We envision a prosperous \n",
      "and inclusive India, in which the fruits of development reach all regions and \n",
      "citizens, especially our youth, women, farmers, OBCs, Scheduled Castes and \n",
      "Scheduled Tribes.  \n",
      "2. In the 75 th year of our Independence, the world has recognised the \n",
      "Indian economy as a ‘bright star’. Our current year’s economic growth is \n",
      "estimated to be at 7 per cent. It is notable that this is the highest among all \n",
      "the major economies. This is in spite of the massive slowdown globally \n",
      "caused by Covid-19 and a war. The Indian economy is therefore on the right \n",
      "track, and despite a time of challenges, heading towards a bright future.  \n",
      "3. Today as Indians stands with their head held high, and the world \n",
      "appreciates India’s achievements and successes, we are sure that elders \n",
      "who had fought for India’s independence, will with joy, bless us our \n",
      "endeavors going forward. \n",
      "Resilience amidst multiple crises \n",
      "4. Our focus on wide-ranging reforms and sound policies, implemented \n",
      "through Sabka Prayas  resulting in Jan Bhagidari  and targeted support to \n",
      "those in need, helped us perform well in trying times. India’s rising global\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b24dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Adobe Acrobat Pro 10.1.16', 'creator': 'Adobe Acrobat Pro 10.1.16', 'creationdate': '2023-02-01T05:28:04+05:30', 'moddate': '2023-02-01T08:28:21+05:30', 'title': '', 'source': 'documents/budget_speech.pdf', 'total_pages': 58, 'page': 4, 'page_label': '5'}\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d45de3",
   "metadata": {},
   "source": [
    "chunk_size\n",
    "Definition: Maximum number of characters (or tokens, depending on splitter) per chunk.\n",
    "It determines how big each chunk of text will be.\n",
    "\n",
    "chunk_overlap\n",
    "Definition: Number of characters to repeat between consecutive chunks\n",
    "Keeps context across chunk boundaries\n",
    "Prevents cutting off important sentences in retrieval\n",
    "\n",
    "Chunk size should be chosen based on the embedding model you’re using, because embeddings have practical token limits and performance considerations. Let me explain carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3280746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the document into chunks\n",
    "\n",
    "def chunk_data(docs, chunk_size=8000, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e732afd",
   "metadata": {},
   "source": [
    "Chunking is per Document\n",
    "The splitter works on each Document independently\n",
    "In your case, the page (Document) is only 900 chars\n",
    "Since 900 < 8000\n",
    "The entire page becomes a single chunk\n",
    "No text from the next page is added\n",
    "So you don’t “spill over” to the next page\n",
    "Overlap is irrelevant here\n",
    "Overlap only matters if the Document produces multiple chunks\n",
    "For a single-chunk Document, nothing is repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ea75b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=chunk_data(docs=doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x1399df8e0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1399dffd0>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Embedings of OPen Ai\n",
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c380408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = embeddings.embed_query(\"hello world\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e5912e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehareddy/Desktop/LLM_app/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#create vector search DB in pinecone\n",
    "\n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "index = pc.Index(\"langchainvector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0237d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38d94490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1d932890-2e7c-4f08-97e7-e0592e180daa',\n",
       " 'd26214d4-7be3-455b-89a0-ff2f8d16994d',\n",
       " '4b88b42b-9bd0-4fb2-a21e-4edb46bea836',\n",
       " 'ad6837f4-7a9b-4b26-86f6-cefe73acd9be',\n",
       " '1fc5ea22-5ea3-45b4-b589-42a7818b1249',\n",
       " '33d0e2d9-7b74-42fb-8628-04f0f882f139',\n",
       " 'e6514da7-464c-47c7-9f7f-198b2068e120',\n",
       " '4207e58a-3976-492b-b34e-9d039d7b009f',\n",
       " '71127c26-c67c-4213-8159-28ad9b6dd320',\n",
       " '084664d2-6670-4a4a-b5b7-f5b9b8cfbe5f',\n",
       " '06ad26d9-bdf6-4f7a-b601-b441d43686cb',\n",
       " '20414589-992f-42af-b336-23eb93e6c1f1',\n",
       " '507f625d-8af0-4d0b-b821-3aa18dafcf63',\n",
       " 'e7970a41-9a6e-481b-806d-84443b3a32d7',\n",
       " '202fa2db-7af4-415b-8759-73feb1913660',\n",
       " '970130a9-8836-404c-81f1-43940d36ce74',\n",
       " 'c27ce2e2-ba68-49b1-8549-c96c76d72aea',\n",
       " '42726860-0b54-4d9d-82ba-fec7f7ca8ce0',\n",
       " 'e70469bf-1c21-488c-9126-72f24a5b558f',\n",
       " 'ff39fafe-dc33-491e-826f-49ed825364c3',\n",
       " '78f1adc1-55c6-4fa5-b596-f4875146d797',\n",
       " '4d48020f-1087-4cca-bbc1-4dc9c014b309',\n",
       " '69e7839b-769d-4784-ae19-9cc329ee2ae5',\n",
       " 'e5ed6a9e-b9e7-414b-a208-ac4e2bf1fa0e',\n",
       " 'ed8186d2-eee6-40f3-b008-60772b3481d6',\n",
       " '50c4bce5-9d68-417e-9d5b-7e0eed172114',\n",
       " 'bc0f0780-ddf8-4e91-907f-48f736332af8',\n",
       " '8ac5af2c-b851-47ea-87eb-7a83aba47ad7',\n",
       " '8a0c4d02-3a27-4a1d-b4e4-4616b50be12b',\n",
       " '9d6c8fa4-1c5f-4490-9d1d-878a8c589bd7',\n",
       " '0d0e2092-4d20-46ac-9c25-c1b4cc0fd669',\n",
       " '22be9f9c-eba2-4483-8469-2484963a93f6',\n",
       " '82539be9-f3ef-490f-8745-7269d7715603',\n",
       " '52d5b7dc-7d79-475e-88b7-477f7f0f6527',\n",
       " 'a38c82ad-b66f-4d24-a9ce-4a2777bc941f',\n",
       " 'fdb18624-1004-402b-8205-686cf5a52853',\n",
       " '30b5d175-d1c7-4256-8d68-de850a8f77e5',\n",
       " 'ab694616-1c13-4d09-b8ae-aeb8b2c9657b',\n",
       " '30a47ca9-ba7a-446b-b9ca-bcd00aa472aa',\n",
       " '7e61f34b-5dc6-4369-907d-f85ed63c41b7',\n",
       " 'dd64a798-4650-4baa-9448-bcb077b18d29',\n",
       " '626b5fbf-183f-409d-a326-a455e43f2287',\n",
       " '3e0f7250-b62f-45bd-91b8-cac252b95abe',\n",
       " 'f7ddad9b-c4fe-4b5b-b732-41b61b59163e',\n",
       " 'c0182f0e-1e53-4aaf-9ee6-ae74385ede8b',\n",
       " 'f916943c-19b4-4b98-b6c6-61cc29e05696',\n",
       " '0aac8769-99b9-418a-8501-5d754329b83a',\n",
       " 'fafd0ba5-c0ff-4b2f-b453-321357f6c73e',\n",
       " '192cc093-170e-4986-aca6-21f860575bf5',\n",
       " '056a693c-b4fe-4ae9-81f6-11c1b856d8e3',\n",
       " 'c9592643-8c32-4c9e-b0de-202b0a5c9f9e',\n",
       " '65501ce3-446c-498f-ac0e-96184be32b13',\n",
       " '68f3c9e2-ee1e-466c-9fe4-efaea97be44f',\n",
       " 'd2871a79-d2a1-45fd-8b3e-e8ded028b781',\n",
       " '498567eb-bc28-4acd-a89e-3dff3f309b64',\n",
       " '52776913-14c3-46c1-90fe-bce3f88dd134']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity retrive results from vector DB\n",
    "def retrive_query(query, k=2):\n",
    "    matching_results = vector_store.similarity_search_with_score(query, k=k)\n",
    "    return matching_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109def5",
   "metadata": {},
   "source": [
    "Explanation (plain English)\n",
    "query → user question\n",
    "k=2 → return the top 2 most similar documents\n",
    "similarity_search_with_score:\n",
    "Converts the query into an embedding\n",
    "Compares it with stored vectors using cosine similarity\n",
    "Returns:\n",
    "[\n",
    "  (Document, similarity_score),\n",
    "  ...\n",
    "]\n",
    "So this function retrieves the most relevant documents from the vector database.\n",
    "\n",
    "Why cosine similarity?\n",
    "\n",
    "Measures the angle between vectors\n",
    "Ignores magnitude, focuses on semantic meaning\n",
    "Best for text embeddings\n",
    "Default metric for most LLM embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33b008ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.question_answering import load_qa_chain #Takes retrieved documents,Injects them into an LLM prompt,Produces a final answer\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6618731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # MUST call this first\n",
    "# Verify the key is loaded\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))  # Should print your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "facd90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/ft7fvwms54jbw6rr6knmyd1m0000gn/T/ipykernel_91176/100385751.py:5: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain=load_qa_chain(llm, chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "chain=load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1447ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_answer(query):\n",
    "    doc_search = retrive_query(query)\n",
    "    print(doc_search)\n",
    "    docs = [doc for doc, score in doc_search]\n",
    "    response=chain.run(input_documents=docs, question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36e6094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='71127c26-c67c-4213-8159-28ad9b6dd320', metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 10.0, 'page_label': '11', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content=\"7 \\n \\n \\n \\nfarmers in contributing to the health of fellow citizens by growing these \\n‘Shree Anna’.  \\n22. Now to make India a global hub for ' Shree Anna', the Indian Institute \\nof Millet Research, Hyderabad will be supported as the Centre of Excellence \\nfor sharing best practices, research and technologies at the international \\nlevel.    \\nAgriculture Credit  \\n23. The agriculture credit target will be increased  \\nto ` 20 lakh crore with focus on animal husbandry, dairy and fisheries.  \\nFisheries \\n24. We will launch a new sub-scheme of PM Matsya Sampada Yojana \\nwith targeted investment of ` 6,000 crore to further enable activities of \\nfishermen, fish vendors, and micro & small enterprises, improve value chain \\nefficiencies, and expand the market. \\nCooperation \\n25. For farmers, especially small and marginal farmers, and other \\nmarginalised sections, the government is promoting cooperative-based \\neconomic development model. A new Ministry of Cooperation was formed \\nwith a mandate to realise the vision of ‘Sahakar Se Samriddhi’ . To realise \\nthis vision, the government has already initiated computerisation of 63,000 \\nPrimary Agricultural Credit Societies (PACS) with an investment of ` 2,516 \\ncrore. In consultation with all stakeholders and states, model bye-laws for \\nPACS were formulated enabling them to become multipurpose PACS. A \\nnational cooperative database is being prepared for country-wide mapping \\nof cooperative societies.  \\n26. With this backdrop, we will implement a plan to set up massive \\ndecentralised storage capacity. This will help farmers store their produce \\nand realize remunerative prices through sale at appropriate times. The \\ngovernment will also facilitate setting up of a large number of multipurpose\"), 0.851074219), (Document(id='e7970a41-9a6e-481b-806d-84443b3a32d7', metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 15.0, 'page_label': '16', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content='12 \\n \\n \\n \\nSupport to State Governments for Capital Investment \\n47. I have decided to continue the 50-year interest free loan to state \\ngovernments for one more year to spur investment in infrastructure and to \\nincentivize them for complementary policy actions, with a significantly \\nenhanced outlay of ` 1.3 lakh crore.   \\nEnhancing opportunities for private investment in Infrastructure \\n48. The newly established Infrastructure Finance Secretariat will assist \\nall stakeholders for more private investment in infrastructure, including \\nrailways, roads, urban infrastructure and power, which are predominantly \\ndependent on public resources.  \\nHarmonized Master List of Infrastructure \\n49. The Harmonized Master List of Infrastructure will be reviewed by an \\nexpert committee for recommending the classification and financing \\nframework suitable for Amrit Kaal. \\nRailways \\n50. A capital outlay of ` 2.40 lakh crore has been provided for the \\nRailways. This highest ever outlay is about 9 times the outlay made in 2013-\\n14.  \\nLogistics \\n51. One hundred critical transport infrastructure projects, for last and \\nfirst mile connectivity for ports, coal, steel, fertilizer, and food grains sectors \\nhave been identified. They will be taken up on priority with investment of \\n` 75,000 crore, including ` 15,000 crore from private sources. \\nRegional Connectivity \\n52. Fifty additional airports, heliports, water aerodromes and advance \\nlanding grounds will be revived for improving regional air connectivity.'), 0.834533691)]\n",
      " The agriculture credit target will be increased to ` 20 lakh crore.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"How much the agriculture target will be increased by how many crore?\"\n",
    "answer = retrive_answer(our_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f7270fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='71127c26-c67c-4213-8159-28ad9b6dd320', metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 10.0, 'page_label': '11', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content=\"7 \\n \\n \\n \\nfarmers in contributing to the health of fellow citizens by growing these \\n‘Shree Anna’.  \\n22. Now to make India a global hub for ' Shree Anna', the Indian Institute \\nof Millet Research, Hyderabad will be supported as the Centre of Excellence \\nfor sharing best practices, research and technologies at the international \\nlevel.    \\nAgriculture Credit  \\n23. The agriculture credit target will be increased  \\nto ` 20 lakh crore with focus on animal husbandry, dairy and fisheries.  \\nFisheries \\n24. We will launch a new sub-scheme of PM Matsya Sampada Yojana \\nwith targeted investment of ` 6,000 crore to further enable activities of \\nfishermen, fish vendors, and micro & small enterprises, improve value chain \\nefficiencies, and expand the market. \\nCooperation \\n25. For farmers, especially small and marginal farmers, and other \\nmarginalised sections, the government is promoting cooperative-based \\neconomic development model. A new Ministry of Cooperation was formed \\nwith a mandate to realise the vision of ‘Sahakar Se Samriddhi’ . To realise \\nthis vision, the government has already initiated computerisation of 63,000 \\nPrimary Agricultural Credit Societies (PACS) with an investment of ` 2,516 \\ncrore. In consultation with all stakeholders and states, model bye-laws for \\nPACS were formulated enabling them to become multipurpose PACS. A \\nnational cooperative database is being prepared for country-wide mapping \\nof cooperative societies.  \\n26. With this backdrop, we will implement a plan to set up massive \\ndecentralised storage capacity. This will help farmers store their produce \\nand realize remunerative prices through sale at appropriate times. The \\ngovernment will also facilitate setting up of a large number of multipurpose\"), 0.856079161), (Document(id='4207e58a-3976-492b-b34e-9d039d7b009f', metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 9.0, 'page_label': '10', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content=\"6 \\n \\n \\n \\ninclusive, farmer-centric solutions through relevant information services for \\ncrop planning and health, improved access to farm inputs, credit, and \\ninsurance, help for crop estimation, market intelligence, and support for \\ngrowth of agri-tech industry and start-ups.  \\nAgriculture Accelerator Fund \\n17. An Agriculture Accelerator Fund will be set-up to encourage agri-\\nstartups by young entrepreneurs in rural areas. The Fund will aim at \\nbringing innovative and affordable solutions for challenges faced by \\nfarmers. It will also bring in modern technologies to transform agricultural \\npractices, increase productivity and profitability. \\nEnhancing productivity of cotton crop  \\n18. To enhance the productivity of extra-long staple cotton, we will \\nadopt a cluster-based and value chain approach through Public Private \\nPartnerships (PPP). This will mean collaboration between farmers, state and \\nindustry for input supplies, extension services, and market linkages. \\nAtmanirbhar Horticulture Clean Plant Program  \\n19. We will launch an Atmanirbhar Clean Plant Program to boost \\navailability of disease-free, quality planting material for high value \\nhorticultural crops at an outlay of ` 2,200 crore. \\nGlobal Hub for Millets: ‘Shree Anna’ \\n20. “India is at the forefront of popularizing Millets, whose consumption \\nfurthers nutrition, food security and welfare of farmers,” said Hon’ble Prime \\nMinister. \\n21.  We are the largest producer and second largest exporter of ‘Shree \\nAnna’ in the world. We grow several types of ' Shree Anna'  such as  jowar, \\nragi, bajra, kuttu, ramdana, kangni, kutki, kodo, cheena, and sama. These \\nhave a number of health benefits, and have been an integral part of our \\nfood for centuries. I acknowledge with pride the huge service done by small\"), 0.837524533)]\n",
      " The agriculture credit target will be increased to ` 20 lakh crore.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"how much the agriculture target will be increased by how many crore?\"\n",
    "answer = retrive_answer(our_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07401282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
